{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTM8pDv-fUpT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "BASE = Path('/content/drive/MyDrive/Research/CASTING ARTICLE/casting_512x512')\n",
        "for item in sorted(BASE.iterdir()):\n",
        "    if item.is_dir():\n",
        "        print(f'  ðŸ“ {item.name}/')\n",
        "    else:\n",
        "        print(f'  ðŸ“„ {item.name}')\n",
        "ext_counts = defaultdict(int)\n",
        "folder_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for root, dirs, files in os.walk(BASE):\n",
        "    dirs.sort()\n",
        "    level = Path(root).relative_to(BASE)\n",
        "    indent = '  ' * len(level.parts)\n",
        "    folder_name = Path(root).name\n",
        "\n",
        "    # Count files by extension\n",
        "    file_exts = defaultdict(int)\n",
        "    for f in files:\n",
        "        ext = Path(f).suffix.lower()\n",
        "        file_exts[ext] += 1\n",
        "        ext_counts[ext] += 1\n",
        "\n",
        "    if files:\n",
        "        ext_summary = ', '.join([f'{v} {k}' for k,v in file_exts.items()])\n",
        "        print(f'  {indent}ðŸ“ {folder_name}/ â†’ [{ext_summary}]')\n",
        "    else:\n",
        "        print(f'  {indent}ðŸ“ {folder_name}/ â†’ [empty]')\n",
        "for ext, count in sorted(ext_counts.items()):\n",
        "    print(f'  {ext or \"no extension\"}: {count} files')\n",
        "print('\\n[4] LABEL FORMAT CHECK:')\n",
        "txt_files = list(BASE.rglob('*.txt'))\n",
        "yaml_files = list(BASE.rglob('*.yaml')) + list(BASE.rglob('*.yml'))\n",
        "print(f'  .txt label files found: {len(txt_files)}')\n",
        "print(f'  .yaml config files found: {len(yaml_files)}')\n",
        "\n",
        "if txt_files:\n",
        "    sample_label = txt_files[0]\n",
        "    print(f'\\n  Sample label file: {sample_label.relative_to(BASE)}')\n",
        "    print(f'  Contents: {sample_label.read_text().strip()[:200]}')\n",
        "\n",
        "if yaml_files:\n",
        "    for y in yaml_files:\n",
        "        print(f'\\n  YAML file: {y.relative_to(BASE)}')\n",
        "        print(f'  Contents:\\n{y.read_text().strip()}')\n",
        "all_image_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
        "class_counts = defaultdict(int)\n",
        "all_images = []\n",
        "\n",
        "for root, dirs, files in os.walk(BASE):\n",
        "    folder = Path(root).name.lower()\n",
        "    for f in files:\n",
        "        if Path(f).suffix.lower() in all_image_exts:\n",
        "            all_images.append(Path(root) / f)\n",
        "            class_counts[folder] += 1\n",
        "\n",
        "print(f'  Total images found: {len(all_images)}')\n",
        "for cls, count in sorted(class_counts.items()):\n",
        "    pct = count / len(all_images) * 100 if all_images else 0\n",
        "    print(f'  Folder \"{cls}\": {count} images ({pct:.1f}%)')\n",
        "print('\\n[6] SAMPLE IMAGE PATHS (first 3):')\n",
        "for img in all_images[:3]:\n",
        "    print(f'  {img.relative_to(BASE)}')\n",
        "print('\\n[7] SPLIT DETECTION:')\n",
        "split_keywords = ['train', 'val', 'test', 'valid']\n",
        "found_splits = []\n",
        "for kw in split_keywords:\n",
        "    matches = [p for p in BASE.rglob('*') if kw in p.name.lower() and p.is_dir()]\n",
        "    if matches:\n",
        "        found_splits.append(kw)\n",
        "        for m in matches:\n",
        "            print(f'  âœ… Found \"{kw}\" folder: {m.relative_to(BASE)}')\n",
        "if not found_splits:\n",
        "    print('  âš ï¸  No train/val split folders detected â€” raw class folders only')\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print('ASSESSMENT COMPLETE â€” Share this output')\n",
        "print('=' * 60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q\n",
        "\n",
        "import os, shutil, random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "BASE     = Path('/content/drive/MyDrive/Research/CASTING ARTICLE/casting_512x512')\n",
        "WORK_DIR = Path('/content/casting_work')  # fast local SSD\n",
        "SEED     = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "CLASS_MAP = {'def_front': 0, 'ok_front': 1}\n",
        "\n",
        "all_images = []  # list of (Path, class_int)\n",
        "for folder, cls_id in CLASS_MAP.items():\n",
        "    imgs = sorted((BASE / folder).glob('*.jpeg'))\n",
        "    all_images.extend([(p, cls_id) for p in imgs])\n",
        "\n",
        "random.shuffle(all_images)  # shuffle with fixed seed\n",
        "\n",
        "print(f'Total images collected : {len(all_images)}')\n",
        "print(f'  def_front (cls 0)    : {sum(1 for _,c in all_images if c==0)}')\n",
        "print(f'  ok_front  (cls 1)    : {sum(1 for _,c in all_images if c==1)}')\n",
        "\n",
        "# â”€â”€ Stratified split: 1170 train / 130 val â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def stratified_split(data, val_count=130, seed=42):\n",
        "    random.seed(seed)\n",
        "    class0 = [x for x in data if x[1] == 0]\n",
        "    class1 = [x for x in data if x[1] == 1]\n",
        "\n",
        "    # Proportional val split\n",
        "    ratio = len(class0) / len(data)\n",
        "    val0  = int(round(val_count * ratio))\n",
        "    val1  = val_count - val0\n",
        "\n",
        "    random.shuffle(class0)\n",
        "    random.shuffle(class1)\n",
        "\n",
        "    val_set   = class0[:val0]   + class1[:val1]\n",
        "    train_set = class0[val0:]   + class1[val1:]\n",
        "\n",
        "    print(f'\\nStratified split:')\n",
        "    print(f'  Train : {len(train_set)} images  '\n",
        "          f'(def:{sum(1 for _,c in train_set if c==0)}, '\n",
        "          f'ok:{sum(1 for _,c in train_set if c==1)})')\n",
        "    print(f'  Val   : {len(val_set)} images  '\n",
        "          f'(def:{sum(1 for _,c in val_set if c==0)}, '\n",
        "          f'ok:{sum(1 for _,c in val_set if c==1)})')\n",
        "    return train_set, val_set\n",
        "\n",
        "TRAIN_ALL, VAL_SET = stratified_split(all_images, val_count=130)\n",
        "\n",
        "LABEL_LINE = lambda cls_id: f'{cls_id} 0.5000 0.5000 1.0000 1.0000\\n'\n",
        "\n",
        "VAL_IMG_DIR = WORK_DIR / 'val/images'\n",
        "VAL_LBL_DIR = WORK_DIR / 'val/labels'\n",
        "VAL_IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VAL_LBL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for img_path, cls_id in VAL_SET:\n",
        "    shutil.copy(img_path, VAL_IMG_DIR / img_path.name)\n",
        "    (VAL_LBL_DIR / (img_path.stem + '.txt')).write_text(\n",
        "        LABEL_LINE(cls_id))\n",
        "\n"
      ],
      "metadata": {
        "id": "4gNudtQTgwQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "TRAINING_SIZES = [200, 400, 600, 900, 1170]\n",
        "RESULTS = {}  # store metrics per size\n",
        "\n",
        "for N in TRAINING_SIZES:\n",
        "    print(f'\\n{\"=\"*55}')\n",
        "    print(f'  TRAINING WITH {N} IMAGES  ({N/1170*100:.0f}% of full set)')\n",
        "    print(f'{\"=\"*55}')\n",
        "    t_start = time.time()\n",
        "\n",
        "    RUN_DIR     = WORK_DIR / f'run_{N}'\n",
        "    TRAIN_IMG   = RUN_DIR / 'train/images'\n",
        "    TRAIN_LBL   = RUN_DIR / 'train/labels'\n",
        "    TRAIN_IMG.mkdir(parents=True, exist_ok=True)\n",
        "    TRAIN_LBL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    random.seed(SEED)  # reset seed for reproducibility\n",
        "    cls0_pool = [x for x in TRAIN_ALL if x[1] == 0]\n",
        "    cls1_pool = [x for x in TRAIN_ALL if x[1] == 1]\n",
        "    random.shuffle(cls0_pool)\n",
        "    random.shuffle(cls1_pool)\n",
        "\n",
        "    ratio     = len(cls0_pool) / len(TRAIN_ALL)\n",
        "    n_cls0    = int(round(N * ratio))\n",
        "    n_cls1    = N - n_cls0\n",
        "\n",
        "    selected  = cls0_pool[:n_cls0] + cls1_pool[:n_cls1]\n",
        "    random.shuffle(selected)\n",
        "\n",
        "    print(f'  Selected: {n_cls0} defective + {n_cls1} ok = {len(selected)} total')\n",
        "\n",
        "    for img_path, cls_id in selected:\n",
        "        shutil.copy(img_path, TRAIN_IMG / img_path.name)\n",
        "        (TRAIN_LBL / (img_path.stem + '.txt')).write_text(\n",
        "            LABEL_LINE(cls_id))\n",
        "\n",
        "    data_cfg = {\n",
        "        'path' : str(RUN_DIR),\n",
        "        'train': 'train/images',\n",
        "        'val'  : str(WORK_DIR / 'val/images'),  # fixed val\n",
        "        'nc'   : 2,\n",
        "        'names': {0: 'defective', 1: 'non_defective'}\n",
        "    }\n",
        "    yaml_path = RUN_DIR / 'data.yaml'\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(data_cfg, f, default_flow_style=False)\n",
        "\n",
        "    model = YOLO('yolov8s.pt')\n",
        "    model.train(\n",
        "        data         = str(yaml_path),\n",
        "        epochs       = 80,\n",
        "        imgsz        = 640,\n",
        "        batch        = 16,\n",
        "        optimizer    = 'Adam',\n",
        "        lr0          = 0.01,\n",
        "        lrf          = 0.1,          # final lr = lr0 * lrf = 0.001\n",
        "        weight_decay = 0.0005,\n",
        "        seed         = SEED,\n",
        "        hsv_h        = 0.0,          # no hue shift (grayscale images)\n",
        "        hsv_s        = 0.0,          # no saturation shift\n",
        "        hsv_v        = 0.4,          # brightness variation\n",
        "        fliplr       = 0.5,\n",
        "        degrees      = 15.0,\n",
        "        scale        = 0.2,\n",
        "        mosaic       = 0.3,\n",
        "        mixup        = 0.2,\n",
        "        label_smoothing = 0.1,\n",
        "        verbose      = False,\n",
        "        project      = str(WORK_DIR / 'runs'),\n",
        "        name         = f'yolov8s_n{N}',\n",
        "        exist_ok     = True\n",
        "    )\n",
        "\n",
        "      val_cfg = {\n",
        "        'path' : str(WORK_DIR),\n",
        "        'train': 'val/images',       # placeholder\n",
        "        'val'  : 'val/images',\n",
        "        'nc'   : 2,\n",
        "        'names': {0: 'defective', 1: 'non_defective'}\n",
        "    }\n",
        "    val_yaml = WORK_DIR / 'val_only.yaml'\n",
        "    with open(val_yaml, 'w') as f:\n",
        "        yaml.dump(val_cfg, f, default_flow_style=False)\n",
        "\n",
        "    metrics = model.val(data=str(val_yaml), verbose=False)\n",
        "\n",
        "    P   = float(metrics.box.p.mean())\n",
        "    R   = float(metrics.box.r.mean())\n",
        "    M50 = float(metrics.box.map50)\n",
        "    M95 = float(metrics.box.map)\n",
        "    F1  = 2*P*R/(P+R) if (P+R) > 0 else 0\n",
        "\n",
        "    RESULTS[N] = {\n",
        "        'precision' : round(P,   4),\n",
        "        'recall'    : round(R,   4),\n",
        "        'mAP50'     : round(M50, 4),\n",
        "        'mAP5095'   : round(M95, 4),\n",
        "        'F1'        : round(F1,  4)\n",
        "    }\n",
        "\n",
        "    elapsed = (time.time() - t_start) / 60\n",
        "    print(f'\\n  âœ… n={N} done in {elapsed:.1f} min')\n",
        "    print(f'     Precision : {P:.4f}')\n",
        "    print(f'     Recall    : {R:.4f}')\n",
        "    print(f'     mAP@0.5   : {M50:.4f}')\n",
        "    print(f'     F1-Score  : {F1:.4f}')\n",
        "\n",
        "    shutil.rmtree(TRAIN_IMG)\n",
        "    shutil.rmtree(TRAIN_LBL)\n"
      ],
      "metadata": {
        "id": "dT1uJYwrg6u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "\n",
        "SAVE_PATH = Path('/content/drive/MyDrive/Research/'\n",
        "                 'CASTING ARTICLE/learning_curve_yolov8s.png')\n",
        "\n",
        "sizes = list(RESULTS.keys())\n",
        "map50 = [RESULTS[n]['mAP50'] for n in sizes]\n",
        "f1    = [RESULTS[n]['F1']    for n in sizes]\n",
        "prec  = [RESULTS[n]['precision'] for n in sizes]\n",
        "rec   = [RESULTS[n]['recall']    for n in sizes]\n",
        "\n",
        "sat_idx = None\n",
        "for i in range(1, len(map50)):\n",
        "    if (map50[i] - map50[i-1]) < 0.005:\n",
        "        sat_idx = i\n",
        "        break\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "fig.suptitle(\n",
        "    'YOLOv8s Learning Curve: Performance vs. Training Set Size\\n'\n",
        "    '(Fixed 130-image validation set, Random seed = 42)',\n",
        "    fontsize=12, fontweight='bold', y=1.02\n",
        ")\n",
        "\n",
        "ax = axes[0]\n",
        "ax.plot(sizes, map50, 'o-', color='#1565C0', linewidth=2.5,\n",
        "        markersize=8, label='mAP@0.5', zorder=5)\n",
        "ax.plot(sizes, f1,    's--', color='#C62828', linewidth=2.5,\n",
        "        markersize=8, label='F1-Score', zorder=5)\n",
        "\n",
        "for i, n in enumerate(sizes):\n",
        "    ax.annotate(f'{map50[i]:.3f}', (n, map50[i]),\n",
        "                textcoords='offset points', xytext=(0, 10),\n",
        "                ha='center', fontsize=9, color='#1565C0',\n",
        "                fontweight='bold')\n",
        "    ax.annotate(f'{f1[i]:.3f}', (n, f1[i]),\n",
        "                textcoords='offset points', xytext=(0, -16),\n",
        "                ha='center', fontsize=9, color='#C62828',\n",
        "                fontweight='bold')\n",
        "\n",
        "if sat_idx:\n",
        "    sat_x = sizes[sat_idx]\n",
        "    ax.axvspan(sat_x, sizes[-1], alpha=0.10, color='#2E7D32',\n",
        "               label=f'Saturation zone (>{sat_x} images)')\n",
        "    ax.axvline(x=sat_x, color='#2E7D32', linestyle=':',\n",
        "               linewidth=2, alpha=0.8)\n",
        "    ax.text(sat_x + 35, min(map50) + 0.005,\n",
        "            f'Saturation\\n>{sat_x} images',\n",
        "            fontsize=8, color='#2E7D32', alpha=0.9)\n",
        "\n",
        "ax.set_xlabel('Training Set Size (images)', fontsize=8)\n",
        "ax.set_ylabel('Performance Score', fontsize=11)\n",
        "ax.set_title('(a) Detection Performance', fontsize=8)\n",
        "ax.set_xticks(sizes)\n",
        "ax.set_xticklabels([str(n) for n in sizes])\n",
        "ax.set_ylim([min(min(map50), min(f1)) - 0.02, 1.005])\n",
        "ax.legend(loc='lower right', fontsize=9)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "# Panel (b) â€” Precision and Recall separately\n",
        "ax2 = axes[1]\n",
        "ax2.plot(sizes, prec, '^-',  color='#6A1B9A', linewidth=2.5,\n",
        "         markersize=8, label='Precision', zorder=5)\n",
        "ax2.plot(sizes, rec,  'D--', color='#E65100', linewidth=2.5,\n",
        "         markersize=8, label='Recall',    zorder=5)\n",
        "\n",
        "for i, n in enumerate(sizes):\n",
        "    ax2.annotate(f'{prec[i]:.3f}', (n, prec[i]),\n",
        "                 textcoords='offset points', xytext=(0, 10),\n",
        "                 ha='center', fontsize=9, color='#6A1B9A',\n",
        "                 fontweight='bold')\n",
        "    ax2.annotate(f'{rec[i]:.3f}', (n, rec[i]),\n",
        "                 textcoords='offset points', xytext=(0, -16),\n",
        "                 ha='center', fontsize=9, color='#E65100',\n",
        "                 fontweight='bold')\n",
        "\n",
        "if sat_idx:\n",
        "    ax2.axvspan(sat_x, sizes[-1], alpha=0.10, color='#2E7D32')\n",
        "    ax2.axvline(x=sat_x, color='#2E7D32', linestyle=':',\n",
        "                linewidth=2, alpha=0.8)\n",
        "\n",
        "ax2.set_xlabel('Training Set Size (images)', fontsize=11)\n",
        "ax2.set_ylabel('Performance Score', fontsize=11)\n",
        "ax2.set_title('(b) Precisionâ€“Recall Breakdown', fontsize=8)\n",
        "ax2.set_xticks(sizes)\n",
        "ax2.set_xticklabels([str(n) for n in sizes])\n",
        "ax2.set_ylim([min(min(prec), min(rec)) - 0.02, 1.005])\n",
        "ax2.legend(loc='lower right', fontsize=9)\n",
        "ax2.grid(False, alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(str(SAVE_PATH), dpi=300, bbox_inches='tight',\n",
        "            facecolor='white')\n",
        "plt.savefig('/content/learning_curve_yolov8s.png',\n",
        "            dpi=300, bbox_inches='tight', facecolor='white')\n"
      ],
      "metadata": {
        "id": "4f-plebvy1Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "all_subset = TRAIN_ALL + VAL_SET\n",
        "\n",
        "rows = []\n",
        "for img_path, cls_id in all_subset:\n",
        "    split = 'val' if (img_path, cls_id) in VAL_SET else 'train'\n",
        "    rows.append({\n",
        "        'filename'  : img_path.name,\n",
        "        'folder'    : img_path.parent.name,\n",
        "        'class_id'  : cls_id,\n",
        "        'class_name': 'defective' if cls_id == 0 else 'non_defective',\n",
        "        'split'     : split\n",
        "    })\n",
        "\n",
        "# Sort for reproducibility\n",
        "rows.sort(key=lambda x: (x['split'], x['folder'], x['filename']))\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Research/CASTING ARTICLE/image_subset_list.csv'\n",
        "with open(save_path, 'w', newline='') as f:\n",
        "    writer = csv.DictWriter(f,\n",
        "             fieldnames=['filename','folder','class_id',\n",
        "                        'class_name','split'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(rows)\n"
      ],
      "metadata": {
        "id": "foZ1ZFUAKI2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data.yaml\n",
        "import yaml\n",
        "\n",
        "cfg = {\n",
        "    'dataset'     : 'Casting Product Image Data for Quality Inspection',\n",
        "    'source'      : 'https://www.kaggle.com/datasets/ravirajsinh45/'\n",
        "                    'real-life-industrial-dataset-of-casting-product',\n",
        "    'subset'      : '1300 images (see image_subset_list.csv)',\n",
        "    'train_images': 1170,\n",
        "    'val_images'  : 130,\n",
        "    'seed'        : 42,\n",
        "    'nc'          : 2,\n",
        "    'names'       : {0: 'defective', 1: 'non_defective'},\n",
        "    'image_size'  : 640,\n",
        "    'note'        : 'Bounding boxes are whole-part annotations. '\n",
        "                    'Class 0=defective (def_front), '\n",
        "                    'Class 1=non_defective (ok_front).'\n",
        "}\n",
        "\n",
        "yaml_path = '/content/drive/MyDrive/Research/CASTING ARTICLE/data.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(cfg, f, default_flow_style=False, sort_keys=False)\n"
      ],
      "metadata": {
        "id": "gFDhdMETKJuI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}